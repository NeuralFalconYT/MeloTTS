{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9J40wZCRHFU"
   },
   "source": [
    "[Mello TTS Training on Custom Dataset](https://github.com/myshell-ai/MeloTTS/blob/main/docs/training.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "FJfipdsfKgU1"
   },
   "outputs": [],
   "source": [
    "#@title for colab\n",
    "# from google.colab import drive\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Set the flag to save in Google Drive\n",
    "# Save_In_Google_Drive = True  # @param {type: \"boolean\"}\n",
    "\n",
    "# if Save_In_Google_Drive:\n",
    "#     drive.mount('/content/gdrive')\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# # Check if Google Drive is mounted\n",
    "# if os.path.exists(\"/content/gdrive/\"):\n",
    "#     # Check if the directory already exists\n",
    "#     MeloTTS_dir = \"/content/gdrive/MyDrive/MeloTTS\"\n",
    "#     if not os.path.exists(MeloTTS_dir):\n",
    "#         os.mkdir(MeloTTS_dir)  # Create the directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_path=os.getcwd()\n",
    "base_path=root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rLQA663nKt3d"
   },
   "outputs": [],
   "source": [
    "\n",
    "# base_path=\"/content/\"\n",
    "%cd $base_path\n",
    "!git clone https://github.com/myshell-ai/MeloTTS.git\n",
    "%cd MeloTTS\n",
    "!pip install .\n",
    "!python -m unidic download\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "C7go6-iZN6lx",
    "outputId": "0a0d3628-d154-4b53-871d-34bf657648fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2d8mqhMf1Ss",
    "outputId": "922cb32a-01cb-44fa-a08e-a8cee3cb6108"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def process_zip(zip_file_path):\n",
    "    global root_path\n",
    "    # Define paths based on root_path\n",
    "    extract_dir = f\"{root_path}/MeloTTS/melo/data/example/wavs\"\n",
    "    metadata_old_path = f\"{extract_dir}/metadata.list\"\n",
    "    metadata_file_path = f\"{root_path}/MeloTTS/melo/data/example/metadata.list\"\n",
    "\n",
    "    # Remove the target directory if it already exists\n",
    "    if os.path.exists(extract_dir):\n",
    "        shutil.rmtree(extract_dir)\n",
    "\n",
    "    # Create the target directory\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "    # Unzip the file to the target directory\n",
    "    os.system(f\"unzip -o {zip_file_path} -d {extract_dir}\")\n",
    "\n",
    "    # Open the old file and read its lines\n",
    "    with open(metadata_old_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Prepend \"data/example/wavs/\" to each line\n",
    "    modified_lines = [\"data/example/wavs/\" + line for line in lines]\n",
    "\n",
    "    # Write the modified lines to a new file\n",
    "    with open(metadata_file_path, 'w') as new_file:\n",
    "        new_file.writelines(modified_lines)\n",
    "\n",
    "    # Remove the old metadata file\n",
    "    os.remove(metadata_old_path)\n",
    "\n",
    "    # Clear the output to keep the environment clean\n",
    "    clear_output()\n",
    "\n",
    "    print(f\"Modified content has been saved to {metadata_file_path}\")\n",
    "    return metadata_file_path\n",
    "# Usage:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified content has been saved to /teamspace/studios/this_studio/MeloTTS/melo/data/example/metadata.list\n"
     ]
    }
   ],
   "source": [
    "zip_file_path = 'RONALDO.zip'  # @param {type: \"string\"}\n",
    "zip_file_path=f\"{root_path}/{zip_file_path}\"\n",
    "metadata_file_path=process_zip(zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/MeloTTS/melo\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "GG4MxtjDW9uf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/95 [00:00<?, ?it/s]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "pytorch_model.bin:   0%|                             | 0.00/440M [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model.bin:  10%|█▉                   | 41.9M/440M [00:00<00:01, 384MB/s]\u001b[A\n",
      "pytorch_model.bin:  19%|███▉                 | 83.9M/440M [00:00<00:00, 399MB/s]\u001b[A\n",
      "pytorch_model.bin:  29%|██████▎               | 126M/440M [00:00<00:00, 408MB/s]\u001b[A\n",
      "pytorch_model.bin:  38%|████████▍             | 168M/440M [00:00<00:00, 412MB/s]\u001b[A\n",
      "pytorch_model.bin:  50%|██████████▉           | 220M/440M [00:00<00:00, 415MB/s]\u001b[A\n",
      "pytorch_model.bin:  62%|█████████████▌        | 273M/440M [00:00<00:00, 419MB/s]\u001b[A\n",
      "pytorch_model.bin:  74%|████████████████▏     | 325M/440M [00:00<00:00, 422MB/s]\u001b[A\n",
      "pytorch_model.bin:  86%|██████████████████▊   | 377M/440M [00:00<00:00, 426MB/s]\u001b[A\n",
      "pytorch_model.bin: 100%|██████████████████████| 440M/440M [00:01<00:00, 416MB/s]\u001b[A\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████████| 95/95 [00:04<00:00, 20.05it/s]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(f\"{root_path}/MeloTTS/melo\")\n",
    "!python preprocess_text.py --metadata $metadata_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QJt9XyO_Sarf"
   },
   "outputs": [],
   "source": [
    "    # \"epochs\": 5000,\n",
    "    # \"batch_size\": 4,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vB0rLF0jSB9k",
    "outputId": "633f2aa3-ba0a-4dff-e901-ee2db0910ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n",
      "\u001b[32m2024-09-15 12:44:00.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata_utils\u001b[0m:\u001b[36m_filter\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mInit dataset...\u001b[0m\n",
      "100%|████████████████████████████████████████| 91/91 [00:00<00:00, 72329.29it/s]\n",
      "\u001b[32m2024-09-15 12:44:00.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata_utils\u001b[0m:\u001b[36m_filter\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mmin: 69; max: 1736\u001b[0m\n",
      "\u001b[32m2024-09-15 12:44:00.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata_utils\u001b[0m:\u001b[36m_filter\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1mskipped: 1, total: 91\u001b[0m\n",
      "buckets: [48, 12, 12, 12, 6, 6, 6]\n",
      "\u001b[32m2024-09-15 12:44:00.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata_utils\u001b[0m:\u001b[36m_filter\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mInit dataset...\u001b[0m\n",
      "100%|██████████████████████████████████████████| 4/4 [00:00<00:00, 59074.70it/s]\n",
      "\u001b[32m2024-09-15 12:44:00.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata_utils\u001b[0m:\u001b[36m_filter\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mmin: 148; max: 552\u001b[0m\n",
      "\u001b[32m2024-09-15 12:44:00.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata_utils\u001b[0m:\u001b[36m_filter\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1mskipped: 0, total: 4\u001b[0m\n",
      "Using noise scaled MAS for VITS2\n",
      "Using duration discriminator for VITS2\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m0.0/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m0.0/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m  2%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m3.2/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m  4%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m8.6/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[35m  7%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m14.0/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[35m  8%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m16.8/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[35m 10%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m20.6/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 12%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m24.2/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 12%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m25.2/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 14%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m30.1/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 15%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m31.9/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 16%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m34.0/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 19%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m39.4/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[35m 20%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m41.9/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[35m 23%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m47.4/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[35m 24%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m50.3/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[35m 24%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m50.3/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[35m 26%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m53.7/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[35m 28%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m57.9/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[35m 29%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m60.6/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 32%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m66.4/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 33%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m69.5/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 36%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m75.2/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 37%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m77.0/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 40%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m82.8/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 41%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m84.7/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 44%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m90.4/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 44%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m90.5/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 44%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m92.3/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 44%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m92.3/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 46%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m94.6/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 48%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m99.7/207.8  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 48%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m100.6/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 51%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m105.6/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 52%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m107.7/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 52%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m107.7/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 52%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m109.0/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 54%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m111.9/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 56%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m116.7/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 57%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m117.4/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 57%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m117.6/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 59%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m121.9/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 61%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m125.8/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 62%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m129.8/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 64%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m133.9/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 65%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m134.2/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 66%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m136.9/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 68%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m140.8/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 68%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m140.8/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 69%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m142.6/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 70%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m146.3/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 72%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m149.2/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 73%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m151.0/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 73%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m151.0/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 75%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m155.4/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 77%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m159.4/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 77%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m159.4/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 79%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m164.8/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 81%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m167.8/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 81%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m168.9/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 84%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m174.1/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 86%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m179.3/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 89%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m184.5/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 91%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m188.7/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 92%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m191.2/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 93%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m192.9/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 94%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m195.1/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 96%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m199.5/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 96%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m199.5/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 97%\u001b[0m \u001b[33m0:00:07\u001b[0m \u001b[32m201.3/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 97%\u001b[0m \u001b[33m0:00:07\u001b[0m \u001b[32m202.6/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 99%\u001b[0m \u001b[33m0:00:07\u001b[0m \u001b[32m205.7/207.8\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/G.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:07\u001b[0m \u001b[32m207.8/207.8\u001b[0m\n",
      "                                                                     \u001b[32mMB         \u001b[0m\n",
      "\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m0.0/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m0.0/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m0.0/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m  1%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m1.1/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m  3%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m6.4/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m  4%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m6.6/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m  4%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m7.5/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[35m  5%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m10.0/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[35m  8%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m15.2/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 11%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m19.9/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 13%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m24.5/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 16%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m29.6/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 18%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m33.5/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 20%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m36.7/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[35m 23%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m42.2/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[35m 25%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m47.5/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[35m 27%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m50.3/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[35m 29%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m53.5/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 30%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m56.9/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 31%\u001b[0m \u001b[33m0:00:01\u001b[0m \u001b[32m58.7/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 32%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m59.8/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 35%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m65.3/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 36%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m67.1/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 36%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m67.8/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 39%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m73.1/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 40%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m75.5/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 41%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m77.0/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 44%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m82.1/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 44%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m82.1/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 44%\u001b[0m \u001b[33m0:00:02\u001b[0m \u001b[32m82.1/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 45%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m83.9/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 47%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m88.4/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 49%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m92.3/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 52%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m96.4/187.0  \u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 54%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m100.6/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[35m 54%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m101.2/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 57%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m106.7/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 57%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m107.3/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 58%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m109.0/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 60%\u001b[0m \u001b[33m0:00:03\u001b[0m \u001b[32m111.9/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 63%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m117.4/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 64%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m119.6/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 66%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m123.8/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 67%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m125.8/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 67%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m125.8/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 69%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m128.3/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 71%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m133.0/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 72%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m134.2/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 74%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m138.5/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 76%\u001b[0m \u001b[33m0:00:04\u001b[0m \u001b[32m142.6/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 77%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m143.9/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 80%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m149.2/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[35m 81%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m151.0/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 82%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m153.5/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 84%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m157.6/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 84%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m157.6/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 85%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m159.4/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 85%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m159.4/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 87%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m163.1/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 89%\u001b[0m \u001b[33m0:00:05\u001b[0m \u001b[32m166.0/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 90%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m167.8/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 90%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m167.8/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 91%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m171.0/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 94%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m175.8/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[35m 95%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m178.2/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m 98%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m183.3/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m186.7/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m186.7/187.0\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2KDownloading \u001b[3;36m…/basespeakers/pretrained/D.pth\u001b[0m \u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:06\u001b[0m \u001b[32m187.0/187.0\u001b[0m\n",
      "                                                                     \u001b[32mMB         \u001b[0m\n",
      "\u001b[2KDownloading \u001b[3;36m…asespeakers/pretrained/DUR.pth\u001b[0m \u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m\n",
      "\u001b[?25h/teamspace/studios/this_studio/MeloTTS/melo/utils.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n",
      "(torch.Size([10, 192]), torch.Size([8, 192]))\n",
      "(torch.Size([256, 256]), torch.Size([1, 256]))\n",
      "list index out of range\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/train.py:252: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=hps.train.fp16_run)\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/train.py:342: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=hps.train.fp16_run):\n",
      "[rank0]:[W915 12:44:20.093552078 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/functional.py:666: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/train.py:391: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=False):\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/train.py:400: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=False):\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/train.py:420: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=hps.train.fp16_run):\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/train.py:425: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=False):\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "grad.sizes() = [1, 9, 96], strides() = [64416, 96, 1]\n",
      "bucket_view.sizes() = [1, 9, 96], strides() = [864, 96, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Evaluating ...\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bert = torch.load(bert_path)\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/data_utils.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spec = torch.load(spec_filename)\n",
      "Evauate done\n",
      "  6%|██▌                                         | 1/17 [00:16<04:20, 16.26s/it]/teamspace/studios/this_studio/MeloTTS/melo/train.py:342: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=hps.train.fp16_run):\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/train.py:391: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=False):\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/train.py:400: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=False):\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/train.py:420: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=hps.train.fp16_run):\n",
      "/teamspace/studios/this_studio/MeloTTS/melo/train.py:425: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=False):\n",
      "100%|███████████████████████████████████████████| 17/17 [00:34<00:00,  2.04s/it]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:09<00:00,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:11<00:00,  1.53it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:09<00:00,  1.76it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:10<00:00,  1.65it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.12it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:07<00:00,  2.13it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.11it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  1.89it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.11it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.01it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.01it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.03it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  1.99it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.11it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  1.96it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.11it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.11it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:07<00:00,  2.14it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:07<00:00,  2.13it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:07<00:00,  2.13it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:07<00:00,  2.13it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.12it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.01it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.12it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:07<00:00,  2.14it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:07<00:00,  2.14it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:07<00:00,  2.13it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.01it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:07<00:00,  2.13it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.11it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.09it/s]\n",
      "100%|███████████████████████████████████████████| 17/17 [00:08<00:00,  2.02it/s]\n",
      " 29%|████████████▉                               | 5/17 [00:02<00:05,  2.11it/s]"
     ]
    }
   ],
   "source": [
    "os.chdir(f\"{root_path}/MeloTTS/melo\")\n",
    "config_path=f\"{root_path}/MeloTTS/melo/data/example/config.json\"\n",
    "!chmod +x train.sh\n",
    "!bash train.sh $config_path 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mO50-Mx8X2NF"
   },
   "outputs": [],
   "source": [
    "os.chdir(f\"{root_path}/MeloTTS/melo\")\n",
    "input_text=\"This is a demo\"\n",
    "train_model_path=\"your_path.pth\"\n",
    "save_audio_path=f\"{root_path}/test.wav\"\n",
    "!python infer.py --text $input_text -m $train_model_path -o $save_audio_path"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
