{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\py_310\\lib\\site-packages\\whisper\\__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "C:\\Users\\sanjib\\AppData\\Local\\Temp\\ipykernel_7536\\1874023451.py:16: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "whisper_model = whisper.load_model(\"tiny.en\")\n",
    "\n",
    "def speech_to_text(audio_file):\n",
    "    result = whisper_model.transcribe(audio_file)\n",
    "    return result['text'].strip()\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import Audio\n",
    "from IPython.core.display import display\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def remove_silence(file_path, silence_threshold=0.1):\n",
    "    # print(f\"Silence Remove\")\n",
    "    global base_path\n",
    "    store_path=f\"{base_path}/remove_silence\"\n",
    "    if not os.path.exists(store_path):\n",
    "      os.makedirs(store_path)\n",
    "    f_name=os.path.basename(file_path)\n",
    "    output_path=f\"{store_path}/{f_name}\"\n",
    "    \"\"\"\n",
    "    Remove or keep silence from an audio file based on the given parameter.\n",
    "\n",
    "    :param file_path: Path to the input audio file.\n",
    "    :param output_path: Path to the output audio file.\n",
    "    :param silence_threshold: Parameter between 0.0 and 1.0 indicating the maximum silence gap to keep.\n",
    "                              0.0 means remove all silence, 1.0 means keep silence gaps of up to 1.0 seconds.\n",
    "    \"\"\"\n",
    "    # Extract file name and format from the provided path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    audio_format = \"wav\"\n",
    "\n",
    "    # Reading the audio file\n",
    "    sound = AudioSegment.from_file(file_path, format=audio_format)\n",
    "\n",
    "    # Convert silence_threshold to milliseconds\n",
    "    max_silence_len = silence_threshold * 1000  # Convert to milliseconds\n",
    "\n",
    "    # Split the audio on silence\n",
    "    audio_chunks = split_on_silence(sound,\n",
    "                                    min_silence_len=1,  # Smallest chunk of silence considered\n",
    "                                    silence_thresh=-45,\n",
    "                                    keep_silence=max_silence_len)\n",
    "\n",
    "    # Combine chunks into one audio segment\n",
    "    combined = AudioSegment.empty()\n",
    "    for chunk in audio_chunks:\n",
    "        combined += chunk\n",
    "    combined = combined.set_frame_rate(44100)\n",
    "    # Export the processed audio\n",
    "    combined.export(output_path, format=audio_format)\n",
    "    # print(f\"Silence Remove\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def get_last_index(dataset_path):\n",
    "  # List of files\n",
    "  old_files = os.listdir(dataset_path)\n",
    "  if old_files:\n",
    "    # Filter to include only .wav files and remove extensions\n",
    "    wav_files = [f for f in old_files if f.endswith('.wav')]\n",
    "    # Sort based on file names without extension\n",
    "    sorted_wav_files = sorted(wav_files, key=lambda x: os.path.splitext(x)[0])\n",
    "\n",
    "    # Get the last file in the sorted list\n",
    "    last_file = sorted_wav_files[-1] if sorted_wav_files else None\n",
    "    last_index=int(last_file.replace(\".wav\",\"\"))\n",
    "    return last_index\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_to_44100hz(input_wav):\n",
    "    global base_path\n",
    "    store_path=f\"{base_path}/remove_silence\"\n",
    "    if not os.path.exists(store_path):\n",
    "      os.makedirs(store_path)\n",
    "    output_wav=f\"{store_path}/44100hz_{os.path.basename(input_wav)}\"\n",
    "    # Load the WAV file\n",
    "    audio = AudioSegment.from_wav(input_wav)\n",
    "    \n",
    "    # Set the frame rate to 44100 Hz\n",
    "    audio = audio.set_frame_rate(44100)\n",
    "    \n",
    "    # Export the file as a new WAV with 44100 Hz format\n",
    "    audio.export(output_wav, format=\"wav\")\n",
    "    return output_wav\n",
    "# Example usage:\n",
    "# convert_to_44100hz(\"input.wav\", \"output_44100hz.wav\")\n",
    "\n",
    "\n",
    "def make_zip(dataset_folder,zip_path):\n",
    "    if os.path.exists(zip_path):\n",
    "        os.remove(zip_path)\n",
    "    with ZipFile(zip_path, 'w') as zipf:\n",
    "        for root, dirs, files in os.walk(dataset_folder):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, dataset_folder)\n",
    "                zipf.write(file_path, arcname=arcname)\n",
    "                \n",
    "def make_dataset(audio_folder,voice_name,language_code_name,update_dataset,no_silence,silence_threshold):\n",
    "    global base_path\n",
    "    dataset_folder=f\"{base_path}/dataset\"\n",
    "    if not os.path.exists(dataset_folder):\n",
    "        os.makedirs(dataset_folder) \n",
    "    original_dataset_folder=f\"{dataset_folder}/{voice_name.strip().upper()}\"\n",
    "    dataset_path = f\"{original_dataset_folder}_with_text\"\n",
    "    model_name = f\"{language_code_name.lower()}-{voice_name.lower()}\"\n",
    "    last_index=0\n",
    "    if update_dataset:\n",
    "       if not os.path.exists(dataset_path):\n",
    "           os.makedirs(dataset_path) \n",
    "       last_index=get_last_index(dataset_path)\n",
    "    else:\n",
    "        if os.path.exists(dataset_path):\n",
    "            shutil.rmtree(dataset_path)\n",
    "        os.makedirs(dataset_path)\n",
    "    metadata_text_file =f\"{dataset_path}/metadata.list\" \n",
    "    if update_dataset:\n",
    "      mode='a'\n",
    "    else:\n",
    "      mode='w'       \n",
    "    with open(metadata_text_file, mode) as f:\n",
    "        for i in os.listdir(audio_folder):\n",
    "            if i.endswith(\".wav\"):\n",
    "                audio_path=f\"{audio_folder}/{i}\"\n",
    "                text=speech_to_text(audio_path)\n",
    "                no_of_words = len(text.split())\n",
    "                if no_of_words >= 3:\n",
    "                    f_name = f\"{last_index:06d}\"\n",
    "                    last_index+=1\n",
    "                    text_filename = f\"{dataset_path}/{f_name}.txt\"\n",
    "                    with open(text_filename, 'w') as text_file:\n",
    "                        text_file.write(text)\n",
    "                    output_wav = f\"{dataset_path}/{f_name}.wav\"\n",
    "                    if no_silence:\n",
    "                        file_path=remove_silence(audio_path, silence_threshold)\n",
    "                    else:\n",
    "                        file_path=convert_to_44100hz(audio_path)\n",
    "                    shutil.copy(file_path, output_wav)\n",
    "                    line = f\"{f_name}.wav|{model_name}|{language_code_name}|{text}\\n\"\n",
    "                    f.write(line)\n",
    "    if os.path.exists(original_dataset_folder):\n",
    "        shutil.rmtree(original_dataset_folder)\n",
    "    os.makedirs(original_dataset_folder)\n",
    "    for i in os.listdir(dataset_path):\n",
    "        selected_file = f\"{dataset_path}/{i}\"\n",
    "        #except .txt files\n",
    "        if not selected_file.endswith(\".txt\"):\n",
    "            shutil.copy(selected_file, original_dataset_folder)\n",
    "    zip_path=f\"{original_dataset_folder}.zip\"\n",
    "    make_zip(original_dataset_folder,zip_path)\n",
    "    return zip_path\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created at c:\\Users\\sanjib\\Downloads\\c\\dataset\\SANJI.zip\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_path=\".\"\n",
    "    your_recorded_audio_folder = \"./audio\"\n",
    "    voice_name = \"Ronaldo\"  # @param {type: \"string\"}\n",
    "    language_code_name = \"EN\"  # @param ['EN', 'ES', 'FR', 'ZH','JA','KO']\n",
    "    update_dataset = False  # @param {type: \"boolean\"}\n",
    "    no_silence=True \n",
    "    silence_threshold=0.1 \n",
    "    zip_path=make_dataset(your_recorded_audio_folder,voice_name,language_code_name,update_dataset,no_silence,silence_threshold)\n",
    "    zip_full_path=os.path.abspath(zip_path)\n",
    "    print(f\"Dataset created at {zip_full_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
